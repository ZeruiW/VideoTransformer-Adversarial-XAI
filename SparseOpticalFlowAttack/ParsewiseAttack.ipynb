{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsewise Attack with Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/z/miniconda3/envs/mmxai/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing videos:  31%|███       | 6167/19796 [5:18:36<12:12:04,  3.22s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import av\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "model = models.resnet101(pretrained=True)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_video_labels(label_file):\n",
    "\n",
    "    video_labels = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            video_name, label = line.strip().split()\n",
    "            video_labels[video_name] = int(label)\n",
    "    return video_labels\n",
    "\n",
    "def generate_adversarial_frame(frame, true_label, target_label, config):\n",
    "\n",
    "    original_size = frame.shape[:2]\n",
    "    \n",
    "    frame_pil = Image.fromarray(frame)\n",
    "    image_tensor = transform(frame_pil).unsqueeze(0).to(device)\n",
    "    image_tensor.requires_grad = True\n",
    "    \n",
    "    target = torch.tensor([target_label], device=device)\n",
    "    output = model(image_tensor)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    classification_loss = criterion(output, target)\n",
    "    \n",
    "\n",
    "    tv_loss = torch.sum(torch.abs(image_tensor[:, :, :, :-1] - image_tensor[:, :, :, 1:])) + \\\n",
    "              torch.sum(torch.abs(image_tensor[:, :, :-1, :] - image_tensor[:, :, 1:, :]))\n",
    "    \n",
    "\n",
    "    l2_loss = torch.norm(image_tensor, p=2)\n",
    "    \n",
    "\n",
    "    loss = classification_loss + config['tv_weight'] * tv_loss + config['l2_weight'] * l2_loss\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    data_grad = image_tensor.grad.data\n",
    "    data_grad = data_grad / (data_grad.norm() + 1e-10)\n",
    "    \n",
    "\n",
    "    perturbed_image = image_tensor + config['epsilon'] * data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "\n",
    "    perturbed_frame = perturbed_image.squeeze(0).cpu().detach().numpy()\n",
    "    perturbed_frame = np.transpose(perturbed_frame, (1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    perturbed_frame = std * perturbed_frame + mean\n",
    "    perturbed_frame = np.clip(perturbed_frame * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    perturbed_frame = cv2.resize(perturbed_frame, (original_size[1], original_size[0]))\n",
    "    \n",
    "    return perturbed_frame\n",
    "\n",
    "def select_keyframes(frames, interval):\n",
    "    num_frames = len(frames)\n",
    "    keyframe_indices = list(range(0, num_frames, interval))\n",
    "    return keyframe_indices\n",
    "\n",
    "def compute_optical_flow(frame1, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "\n",
    "def warp_frame(frame, flow, progress):\n",
    "    h, w = flow.shape[:2]\n",
    "    flow_map = np.column_stack((\n",
    "        progress * flow[..., 0].flatten(),\n",
    "        progress * flow[..., 1].flatten()\n",
    "    ))\n",
    "    \n",
    "    map_x = np.tile(np.arange(w), (h, 1))\n",
    "    map_y = np.tile(np.arange(h), (w, 1)).T\n",
    "    \n",
    "    dst_x = (map_x + flow_map[:, 0].reshape(h, w)).astype(np.float32)\n",
    "    dst_y = (map_y + flow_map[:, 1].reshape(h, w)).astype(np.float32)\n",
    "    \n",
    "    return cv2.remap(frame, dst_x, dst_y, cv2.INTER_LINEAR)\n",
    "\n",
    "def temporal_propagation(frames, keyframe_indices, perturbed_keyframes, config):\n",
    "    all_perturbed_frames = frames.copy()\n",
    "    \n",
    "    for idx, key_idx in enumerate(keyframe_indices):\n",
    "        if perturbed_keyframes[idx].shape != frames[key_idx].shape:\n",
    "            perturbed_keyframes[idx] = cv2.resize(\n",
    "                perturbed_keyframes[idx], \n",
    "                (frames[key_idx].shape[1], frames[key_idx].shape[0])\n",
    "            )\n",
    "\n",
    "        frame = frames[key_idx].astype(np.float32)\n",
    "        perturbed = perturbed_keyframes[idx].astype(np.float32)\n",
    "        \n",
    "\n",
    "        all_perturbed_frames[key_idx] = cv2.addWeighted(\n",
    "            frame, 1 - config['keyframe_weight'],\n",
    "            perturbed, config['keyframe_weight'],\n",
    "            0\n",
    "        ).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    for i in range(len(keyframe_indices)-1):\n",
    "        start_idx = keyframe_indices[i]\n",
    "        end_idx = keyframe_indices[i+1]\n",
    "        \n",
    "        flow_forward = compute_optical_flow(frames[start_idx], frames[end_idx])\n",
    "        flow_backward = compute_optical_flow(frames[end_idx], frames[start_idx])\n",
    "        \n",
    "        for idx in range(start_idx + 1, end_idx):\n",
    "\n",
    "            progress = (idx - start_idx) / (end_idx - start_idx)\n",
    "            weight = np.exp(-((progress - 0.5) ** 2) / config['gaussian_sigma'])\n",
    "            \n",
    "\n",
    "            forward_warped = warp_frame(all_perturbed_frames[start_idx], flow_forward, progress)\n",
    "            backward_warped = warp_frame(all_perturbed_frames[end_idx], flow_backward, 1-progress)\n",
    "            \n",
    "\n",
    "            forward_warped = forward_warped.astype(np.float32)\n",
    "            backward_warped = backward_warped.astype(np.float32)\n",
    "            \n",
    "\n",
    "            perturbation = ((forward_warped + backward_warped) / 2).astype(np.float32)\n",
    "            frame = frames[idx].astype(np.float32)\n",
    "            \n",
    "\n",
    "            temporal_weight = config['propagation_weight'] * weight\n",
    "            all_perturbed_frames[idx] = cv2.addWeighted(\n",
    "                frame, 1 - temporal_weight,\n",
    "                perturbation, temporal_weight,\n",
    "                0\n",
    "            ).astype(np.uint8)\n",
    "    \n",
    "    return all_perturbed_frames\n",
    "\n",
    "def load_video(video_path):\n",
    "    frames = []\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    fps = stream.average_rate\n",
    "    \n",
    "    for frame in container.decode(video=0):\n",
    "        frames.append(frame.to_rgb().to_ndarray())\n",
    "    \n",
    "    return np.stack(frames), fps\n",
    "\n",
    "def save_video(frames, output_path, fps=30):\n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=fps)\n",
    "    \n",
    "    height = frames.shape[1] - (frames.shape[1] % 2)\n",
    "    width = frames.shape[2] - (frames.shape[2] % 2)\n",
    "    \n",
    "    stream.width = width\n",
    "    stream.height = height\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame[:height, :width]\n",
    "        frame = av.VideoFrame.from_ndarray(frame, format='rgb24')\n",
    "        packet = stream.encode(frame)\n",
    "        container.mux(packet)\n",
    "    \n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "def process_videos(config):\n",
    "\n",
    "    video_labels = load_video_labels(config['label_file'])\n",
    "    \n",
    "    adv_video_dir = os.path.join(os.path.dirname(config['video_directory']), 'Sparse_Keyframe2')\n",
    "    os.makedirs(adv_video_dir, exist_ok=True)\n",
    "    \n",
    "    for video_name, true_label in tqdm(video_labels.items(), desc=\"Processing videos\"):\n",
    "        video_path = os.path.join(config['video_directory'], video_name)\n",
    "        \n",
    "        try:\n",
    "            output_subdir = os.path.dirname(video_name)\n",
    "            if output_subdir:\n",
    "                os.makedirs(os.path.join(adv_video_dir, output_subdir), exist_ok=True)\n",
    "            \n",
    "            frames, fps = load_video(video_path)\n",
    "            keyframe_indices = select_keyframes(frames, config['keyframe_interval'])\n",
    "            keyframes = [frames[i] for i in keyframe_indices]\n",
    "            \n",
    "            possible_targets = list(range(config['num_classes']))\n",
    "            possible_targets.remove(true_label)\n",
    "            target_label = np.random.choice(possible_targets)\n",
    "            \n",
    "            perturbed_keyframes = []\n",
    "            for frame in tqdm(keyframes, desc=f\"Processing keyframes in {video_name}\", leave=False):\n",
    "                perturbed_frame = generate_adversarial_frame(\n",
    "                    frame,\n",
    "                    true_label,\n",
    "                    target_label,\n",
    "                    config\n",
    "                )\n",
    "                perturbed_keyframes.append(perturbed_frame)\n",
    "            \n",
    "\n",
    "            perturbed_frames = temporal_propagation(frames, keyframe_indices, perturbed_keyframes, config)\n",
    "            perturbed_frames = np.stack(perturbed_frames)\n",
    "            \n",
    "            output_path = os.path.join(adv_video_dir, video_name)\n",
    "            save_video(perturbed_frames, output_path, fps)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        'video_directory': '/home/z/Music/st/Kinetics-400/RQ1/videos_val',\n",
    "        'label_file': '/home/z/Music/st/Kinetics-400/RQ1/kinetics400_val_list_videos.txt',\n",
    "        'num_classes': 400,  \n",
    "        'epsilon': 0.03,  \n",
    "        'tv_weight': 0.1,  \n",
    "        'l2_weight': 0.01,  \n",
    "        'keyframe_interval': 30,  \n",
    "        'keyframe_weight': 0.02,  \n",
    "        'propagation_weight': 0.15, \n",
    "        'gaussian_sigma': 0.08,  \n",
    "    }\n",
    "    \n",
    "    process_videos(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo Visualization of Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating arrow visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 300/300 [00:09<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating heatmap visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 300/300 [00:10<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import av\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def load_video(video_path):\n",
    "    frames = []\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    fps = stream.average_rate\n",
    "    \n",
    "    for frame in container.decode(video=0):\n",
    "        frames.append(frame.to_rgb().to_ndarray())\n",
    "    \n",
    "    return np.stack(frames), fps\n",
    "\n",
    "def compute_optical_flow(frame1, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return flow\n",
    "\n",
    "def draw_flow(img, flow, step=32):  # 增加步长从16到32，使箭头更稀疏\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step/2:h:step, step/2:w:step].reshape(2,-1).astype(int)\n",
    "    fx, fy = flow[y,x].T\n",
    "    \n",
    "    lines = np.vstack([x, y, x+fx*1.5, y+fy*1.5]).T.reshape(-1, 2, 2)  \n",
    "    lines = np.int32(lines)\n",
    "\n",
    "    vis = img.copy()\n",
    "    \n",
    "\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        if np.sqrt((x2-x1)**2 + (y2-y1)**2) > 1:  \n",
    "            cv2.arrowedLine(vis, (x1, y1), (x2, y2), (0, 255, 0), 3, tipLength=0.4)\n",
    "    \n",
    "    return vis\n",
    "\n",
    "def visualize_optical_flow(video_path, output_path):\n",
    "\n",
    "    frames, fps = load_video(video_path)\n",
    "\n",
    "    height, width = frames[0].shape[:2]\n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=fps)\n",
    "    stream.width = width\n",
    "    stream.height = height\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "\n",
    "    prev_frame = None\n",
    "    for i in tqdm(range(len(frames)), desc=\"Processing frames\"):\n",
    "        current_frame = frames[i]\n",
    "        \n",
    "        if prev_frame is not None:\n",
    "            flow = compute_optical_flow(prev_frame, current_frame)\n",
    "            \n",
    "            flow_vis = draw_flow(current_frame, flow)\n",
    "            \n",
    "            frame = av.VideoFrame.from_ndarray(flow_vis, format='rgb24')\n",
    "            packet = stream.encode(frame)\n",
    "            container.mux(packet)\n",
    "        \n",
    "        prev_frame = current_frame\n",
    "    \n",
    "    # 完成视频写入\n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "def visualize_flow_magnitude(video_path, output_path):\n",
    "\n",
    "    frames, fps = load_video(video_path)\n",
    "\n",
    "    height, width = frames[0].shape[:2]\n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=fps)\n",
    "    stream.width = width\n",
    "    stream.height = height\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "    prev_frame = None\n",
    "    for i in tqdm(range(len(frames)), desc=\"Processing frames\"):\n",
    "        current_frame = frames[i]\n",
    "        \n",
    "        if prev_frame is not None:\n",
    "            flow = compute_optical_flow(prev_frame, current_frame)\n",
    "            \n",
    "            magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "            \n",
    "            magnitude = np.clip(magnitude * 10, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            heatmap = cv2.applyColorMap(magnitude, cv2.COLORMAP_JET)\n",
    "            \n",
    "            overlay = cv2.addWeighted(current_frame, 0.7, heatmap, 0.3, 0)\n",
    "            \n",
    "            frame = av.VideoFrame.from_ndarray(overlay, format='rgb24')\n",
    "            packet = stream.encode(frame)\n",
    "            container.mux(packet)\n",
    "        \n",
    "        prev_frame = current_frame\n",
    "    \n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    \n",
    "    input_video = \"/home/z/Music/st/Kinetics-400/RQ3/example/select/selected/0H3dSeJ58Hc.mp4\"\n",
    "    output_dir = \"/home/z/Music/st/Kinetics-400/RQ3/example/select/ooptical\"\n",
    "    output_video_arrows = os.path.join(output_dir, \"flow_arrows.mp4\")\n",
    "    output_video_heatmap = os.path.join(output_dir, \"flow_heatmap.mp4\")\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 生成带箭头的光流可视化\n",
    "    print(\"Generating arrow visualization...\")\n",
    "    visualize_optical_flow(input_video, output_video_arrows)\n",
    "    \n",
    "    # 生成热力图可视化\n",
    "    print(\"Generating heatmap visualization...\")\n",
    "    visualize_flow_magnitude(input_video, output_video_heatmap)\n",
    "    \n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Pure Adversarial Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import av\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from transformers import TimesformerForVideoClassification, AutoImageProcessor\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def get_video_info(video_path):\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    total_frames = stream.frames\n",
    "    container.close()\n",
    "    return total_frames\n",
    "\n",
    "def load_video_segment(video_path, start_frame, num_frames=8):\n",
    "    frames = []\n",
    "    container = av.open(video_path)\n",
    "    \n",
    "    stream = container.decode(video=0)\n",
    "    for i, frame in enumerate(stream):\n",
    "        if i >= start_frame:\n",
    "            frames.append(frame.to_rgb().to_ndarray())\n",
    "            if len(frames) == num_frames:\n",
    "                break\n",
    "    \n",
    "    container.close()\n",
    "    \n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1] if frames else np.zeros_like(frames[0]))\n",
    "    \n",
    "    return np.stack(frames)\n",
    "\n",
    "def fgsm_attack_with_gradient(model, data, epsilon, labels, device):\n",
    "    \"\"\"\n",
    "    Modified FGSM attack that returns both the gradients and perturbed data\n",
    "    \"\"\"\n",
    "    data.pixel_values.requires_grad = True\n",
    "    \n",
    "    outputs = model(**data)\n",
    "    loss = F.cross_entropy(outputs.logits, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get raw gradients\n",
    "    raw_gradients = data.pixel_values.grad.data.clone()\n",
    "    \n",
    "    # Get gradient sign for FGSM\n",
    "    data_grad = raw_gradients.sign()\n",
    "    \n",
    "    # Generate perturbed data\n",
    "    perturbed_data = data.copy()\n",
    "    perturbed_data.pixel_values = data.pixel_values + epsilon * data_grad\n",
    "    perturbed_data.pixel_values = torch.clamp(perturbed_data.pixel_values, 0, 1)\n",
    "    \n",
    "    return raw_gradients, data_grad, perturbed_data\n",
    "\n",
    "def save_gradient_frames(gradients, output_path):\n",
    "    \"\"\"\n",
    "    Save gradient visualization as video frames\n",
    "    \"\"\"\n",
    "    # Normalize gradients to [0, 1] range for visualization\n",
    "    grad_min = gradients.min()\n",
    "    grad_max = gradients.max()\n",
    "    normalized_grads = (gradients - grad_min) / (grad_max - grad_min)\n",
    "    \n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=30)\n",
    "    stream.width = gradients.shape[3]\n",
    "    stream.height = gradients.shape[2]\n",
    "    \n",
    "    for frame in normalized_grads:\n",
    "        # Convert to grayscale-like visualization\n",
    "        frame = frame.mean(dim=0)  # Average across channels\n",
    "        frame = frame.unsqueeze(2).repeat(1, 1, 3)  # Repeat for RGB channels\n",
    "        frame = frame.cpu().numpy()\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "        frame = av.VideoFrame.from_ndarray(frame, format='rgb24')\n",
    "        packet = stream.encode(frame)\n",
    "        container.mux(packet)\n",
    "    \n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "def process_single_video(config):\n",
    "    \"\"\"\n",
    "    Process a single video and generate gradient visualizations\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = TimesformerForVideoClassification.from_pretrained(config['model_name']).to(device)\n",
    "    processor = AutoImageProcessor.from_pretrained(config['model_name'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = config['output_directory']\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    video_path = config['video_path']\n",
    "    total_frames = get_video_info(video_path)\n",
    "    num_segments = total_frames // 8\n",
    "    \n",
    "    for segment_idx in range(num_segments):\n",
    "        start_frame = segment_idx * 8\n",
    "        \n",
    "        # Load video segment\n",
    "        frames = load_video_segment(video_path, start_frame)\n",
    "        inputs = processor(list(frames), return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Use a dummy label (0) since we're only interested in gradients\n",
    "        labels = torch.tensor([0]).to(device)\n",
    "        \n",
    "        # Generate gradients and FGSM attack\n",
    "        raw_gradients, sign_gradients, perturbed_inputs = fgsm_attack_with_gradient(\n",
    "            model, inputs, config['epsilon'], labels, device\n",
    "        )\n",
    "        \n",
    "        # Save raw gradients\n",
    "        raw_grad_path = os.path.join(output_dir, f'raw_gradients_segment_{segment_idx:04d}.mp4')\n",
    "        save_gradient_frames(raw_gradients[0], raw_grad_path)\n",
    "        \n",
    "        # Save sign gradients\n",
    "        sign_grad_path = os.path.join(output_dir, f'sign_gradients_segment_{segment_idx:04d}.mp4')\n",
    "        save_gradient_frames(sign_gradients[0], sign_grad_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        'model_name': 'facebook/timesformer-base-finetuned-k400',\n",
    "        'video_path': '/home/z/Music/st/Kinetics-400/RQ3/testing/4gNhknocfik.mp4',\n",
    "        'output_directory': '/home/z/Music/st/Kinetics-400/RQ3/testingFGSM/',  # Specify your output directory\n",
    "        'epsilon': 0.3\n",
    "    }\n",
    "    \n",
    "    process_single_video(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatio-Temporal Attack to Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import av\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from transformers import TimesformerForVideoClassification, AutoImageProcessor\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def get_video_info(video_path):\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    total_frames = stream.frames\n",
    "    container.close()\n",
    "    return total_frames\n",
    "\n",
    "def load_video_segment(video_path, start_frame, num_frames=8):\n",
    "    frames = []\n",
    "    container = av.open(video_path)\n",
    "    \n",
    "    stream = container.decode(video=0)\n",
    "    for i, frame in enumerate(stream):\n",
    "        if i >= start_frame:\n",
    "            frames.append(frame.to_rgb().to_ndarray())\n",
    "            if len(frames) == num_frames:\n",
    "                break\n",
    "    \n",
    "    container.close()\n",
    "    \n",
    "    while len(frames) < num_frames:\n",
    "        frames.append(frames[-1] if frames else np.zeros_like(frames[0]))\n",
    "    \n",
    "    return np.stack(frames)\n",
    "\n",
    "def load_labels(label_file):\n",
    "    labels = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            video_name, label = line.strip().split()\n",
    "            labels[video_name.split('.')[0]] = int(label)\n",
    "    return labels\n",
    "\n",
    "def save_segment_info(segment_info, output_path):\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(segment_info, f)\n",
    "\n",
    "def fgsm_attack(model, data, epsilon, labels, device):\n",
    "\n",
    "    data.pixel_values.requires_grad = True\n",
    "    \n",
    "    outputs = model(**data)\n",
    "    loss = F.cross_entropy(outputs.logits, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    data_grad = data.pixel_values.grad.data.sign()\n",
    "    \n",
    "    perturbed_data = data.copy()\n",
    "    perturbed_data.pixel_values = data.pixel_values + epsilon * data_grad\n",
    "    \n",
    "    perturbed_data.pixel_values = torch.clamp(perturbed_data.pixel_values, 0, 1)\n",
    "    \n",
    "    return perturbed_data\n",
    "\n",
    "def save_video_frames(frames, output_path, fps=30):\n",
    "\n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=fps)\n",
    "    stream.width = frames.shape[3]\n",
    "    stream.height = frames.shape[2]\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame.permute(1, 2, 0).numpy()\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "        frame = av.VideoFrame.from_ndarray(frame, format='rgb24')\n",
    "        packet = stream.encode(frame)\n",
    "        container.mux(packet)\n",
    "    \n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "def evaluate_and_generate_adversarial(config):\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = TimesformerForVideoClassification.from_pretrained(config['model_name']).to(device)\n",
    "    processor = AutoImageProcessor.from_pretrained(config['model_name'])\n",
    "    model.eval()\n",
    "\n",
    "    video_labels = load_labels(config['label_file'])\n",
    "    \n",
    "    adv_video_dir = os.path.join(os.path.dirname(config['video_directory']), 'FGSM')\n",
    "    os.makedirs(adv_video_dir, exist_ok=True)\n",
    "\n",
    "    clean_preds = []\n",
    "    adv_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    segment_info = {}\n",
    "\n",
    "    video_files = [f for f in os.listdir(config['video_directory']) if f.endswith('.mp4')]\n",
    "    \n",
    "    for video_file in tqdm(video_files, desc=\"Processing videos\"):\n",
    "        video_name = video_file.split('.')[0]\n",
    "        \n",
    "        if video_name not in video_labels:\n",
    "            continue\n",
    "            \n",
    "        true_label = video_labels[video_name]\n",
    "        video_path = os.path.join(config['video_directory'], video_file)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            total_frames = get_video_info(video_path)\n",
    "            num_segments = total_frames // 8  \n",
    "            \n",
    "            segment_info[video_name] = [1] * num_segments\n",
    "\n",
    "            clean_pred_segments = []\n",
    "            adv_pred_segments = []\n",
    "            \n",
    "            for segment_idx in range(num_segments):\n",
    "                start_frame = segment_idx * 8\n",
    "                \n",
    "\n",
    "                frames = load_video_segment(video_path, start_frame)\n",
    "                inputs = processor(list(frames), return_tensors=\"pt\").to(device)\n",
    "                labels = torch.tensor([true_label]).to(device)\n",
    "                \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    clean_outputs = model(**inputs)\n",
    "                    clean_pred = clean_outputs.logits.argmax(-1).cpu().numpy()[0]\n",
    "                    clean_pred_segments.append(clean_pred)\n",
    "                \n",
    "\n",
    "                perturbed_inputs = fgsm_attack(model, inputs, config['epsilon'], labels, device)\n",
    "                \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    adv_outputs = model(**perturbed_inputs)\n",
    "                    adv_pred = adv_outputs.logits.argmax(-1).cpu().numpy()[0]\n",
    "                    adv_pred_segments.append(adv_pred)\n",
    "                \n",
    "\n",
    "                segment_dir = os.path.join(adv_video_dir, video_name)\n",
    "                os.makedirs(segment_dir, exist_ok=True)\n",
    "                segment_path = os.path.join(segment_dir, f'segment_{segment_idx:04d}.mp4')\n",
    "                adv_frames = perturbed_inputs.pixel_values[0].cpu().detach()\n",
    "                save_video_frames(adv_frames, segment_path)\n",
    "            \n",
    "\n",
    "            clean_pred_final = max(set(clean_pred_segments), key=clean_pred_segments.count)\n",
    "            adv_pred_final = max(set(adv_pred_segments), key=adv_pred_segments.count)\n",
    "            \n",
    "\n",
    "            clean_preds.append(clean_pred_final)\n",
    "            adv_preds.append(adv_pred_final)\n",
    "            all_labels.append(true_label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    segment_info_path = os.path.join(os.path.dirname(config['video_directory']), 'fgsm_segment_info.json')\n",
    "    save_segment_info(segment_info, segment_info_path)\n",
    "    \n",
    "    clean_precision, clean_recall, clean_f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, clean_preds, average='weighted'\n",
    "    )\n",
    "    clean_accuracy = accuracy_score(all_labels, clean_preds)\n",
    "    \n",
    "    adv_precision, adv_recall, adv_f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, adv_preds, average='weighted'\n",
    "    )\n",
    "    adv_accuracy = accuracy_score(all_labels, adv_preds)\n",
    "    \n",
    "    results = {\n",
    "        'clean': {\n",
    "            'accuracy': float(clean_accuracy),\n",
    "            'precision': float(clean_precision),\n",
    "            'recall': float(clean_recall),\n",
    "            'f1': float(clean_f1)\n",
    "        },\n",
    "        'adversarial': {\n",
    "            'accuracy': float(adv_accuracy),\n",
    "            'precision': float(adv_precision),\n",
    "            'recall': float(adv_recall),\n",
    "            'f1': float(adv_f1)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\nClean Performance Metrics:\")\n",
    "    print(f\"Accuracy: {clean_accuracy:.4f}\")\n",
    "    print(f\"Precision: {clean_precision:.4f}\")\n",
    "    print(f\"Recall: {clean_recall:.4f}\")\n",
    "    print(f\"F1 Score: {clean_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nAdversarial Performance Metrics:\")\n",
    "    print(f\"Accuracy: {adv_accuracy:.4f}\")\n",
    "    print(f\"Precision: {adv_precision:.4f}\")\n",
    "    print(f\"Recall: {adv_recall:.4f}\")\n",
    "    print(f\"F1 Score: {adv_f1:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        'model_name': 'facebook/timesformer-base-finetuned-k400',\n",
    "        'video_directory': '/home/z/Music/st/Kinetics-400/RQ3/example/select/selected',\n",
    "        'label_file': '/home/z/Music/st/Kinetics-400/RQ1/kinetics400_val_list_videos.txt',\n",
    "        'epsilon': 0.1\n",
    "    }\n",
    "    \n",
    "    results = evaluate_and_generate_adversarial(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V-BAD (Video-Based Adversarial Density) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/z/Music/st/Kinetics-400/RQ1/videos_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 275\u001b[0m\n\u001b[1;32m    257\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# 文件路径配置\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_directory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/z/Music/st/Kinetics-400/RQ1/videos_val\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_density_map\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    272\u001b[0m }\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# 运行处理\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 216\u001b[0m, in \u001b[0;36mprocess_videos\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    213\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(adv_video_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# 遍历视频目录\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_name \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo_directory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video_name\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/z/Music/st/Kinetics-400/RQ1/videos_val'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.video as video_models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import av\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "class VBAD:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Options\n",
    "        if config['model_type'] == 'r3d_18':\n",
    "            self.model = video_models.r3d_18(pretrained=True)\n",
    "        elif config['model_type'] == 'mc3_18':\n",
    "            self.model = video_models.mc3_18(pretrained=True)\n",
    "        elif config['model_type'] == 'r2plus1d_18':\n",
    "            self.model = video_models.r2plus1d_18(pretrained=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {config['model_type']}\")\n",
    "        \n",
    "\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, config['num_classes'])\n",
    "        \n",
    "        self.model.eval()  \n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((112, 112)),  # 3D CNN通常使用较小的输入尺寸\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                              std=[0.22803, 0.22145, 0.216989])\n",
    "        ])\n",
    "\n",
    "    def preprocess_video(self, frames):\n",
    "        processed_frames = []\n",
    "        for frame in frames:\n",
    "            frame_pil = Image.fromarray(frame)\n",
    "            processed_frame = self.transform(frame_pil)\n",
    "            processed_frames.append(processed_frame)\n",
    "            \n",
    "        # 转换为模型期望的格式 [C, T, H, W]\n",
    "        video_tensor = torch.stack(processed_frames, dim=1)\n",
    "        # 添加batch维度\n",
    "        video_tensor = video_tensor.unsqueeze(0)\n",
    "        return video_tensor.to(self.device)\n",
    "\n",
    "    def generate_density_map(self, video_tensor):\n",
    "        with torch.enable_grad():\n",
    "            C, T, H, W = video_tensor.shape[1:]\n",
    "            density_map = torch.zeros((T, H, W), device=self.device)\n",
    "            \n",
    "            window_size = min(16, T) \n",
    "            stride = window_size // 2\n",
    "            \n",
    "            for t in range(0, T - window_size + 1, stride):\n",
    "                clip = video_tensor[:, :, t:t+window_size].clone()\n",
    "                clip.requires_grad_(True)\n",
    "                \n",
    "                outputs = self.model(clip)\n",
    "                loss = outputs.mean()\n",
    "                \n",
    "                loss.backward(retain_graph=True)\n",
    "                \n",
    "                if clip.grad is not None:\n",
    "                    grad_norm = torch.norm(clip.grad, dim=1, p=2)\n",
    "                    density_map[t:t+window_size] += grad_norm[0]\n",
    "                \n",
    "                clip.grad = None\n",
    "            \n",
    "            if torch.sum(density_map) > 0:\n",
    "                density_map = (density_map - density_map.min()) / (density_map.max() - density_map.min() + 1e-8)\n",
    "            \n",
    "            return density_map\n",
    "\n",
    "    def generate_adversarial_perturbation(self, video_tensor, true_label, target_label):\n",
    "        with torch.enable_grad():\n",
    "            video_tensor = video_tensor.clone()\n",
    "            video_tensor.requires_grad_(True)\n",
    "            \n",
    "            density_map = self.generate_density_map(video_tensor)\n",
    "            \n",
    "            target = torch.tensor([target_label], device=self.device)\n",
    "            \n",
    "            outputs = self.model(video_tensor)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            adv_loss = criterion(outputs, target)\n",
    "            \n",
    "            density_loss = torch.mean(density_map.unsqueeze(0) * torch.norm(video_tensor, dim=1))\n",
    "            \n",
    "            loss = adv_loss + self.config['density_weight'] * density_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if video_tensor.grad is not None:\n",
    "                grad = video_tensor.grad.clone()\n",
    "                grad_norm = torch.norm(grad, p=2)\n",
    "                scaled_grad = grad / (grad_norm + 1e-8)\n",
    "                \n",
    "                perturbation = self.config['epsilon'] * scaled_grad\n",
    "                perturbation = torch.clamp(perturbation, -0.1, 0.1)\n",
    "            else:\n",
    "                perturbation = torch.zeros_like(video_tensor)\n",
    "            \n",
    "            return perturbation, density_map\n",
    "\n",
    "    def apply_perturbation(self, frames):\n",
    "\n",
    "        video_tensor = self.preprocess_video(frames)\n",
    "        \n",
    "        perturbation, density_map = self.generate_adversarial_perturbation(\n",
    "            video_tensor,\n",
    "            self.config['true_label'],\n",
    "            self.config['target_label']\n",
    "        )\n",
    "        \n",
    "        perturbed_video = video_tensor + perturbation\n",
    "        perturbed_video = torch.clamp(perturbed_video, 0, 1)\n",
    "        \n",
    "        perturbed_frames = []\n",
    "        for t in range(perturbed_video.shape[2]):\n",
    "            frame = perturbed_video[0, :, t].cpu().detach().numpy()\n",
    "            frame = np.transpose(frame, (1, 2, 0))\n",
    "\n",
    "\n",
    "            mean = np.array([0.43216, 0.394666, 0.37645])\n",
    "            std = np.array([0.22803, 0.22145, 0.216989])\n",
    "            frame = (frame * std) + mean\n",
    "            \n",
    "            frame = np.clip(frame, 0, 1)\n",
    "            \n",
    "            frame = cv2.resize(frame, (frames[0].shape[1], frames[0].shape[0]), \n",
    "                            interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            frame = (frame * 255).astype(np.uint8)\n",
    "            perturbed_frames.append(frame)\n",
    "        \n",
    "        return perturbed_frames, density_map.cpu().numpy()\n",
    "\n",
    "\n",
    "def load_video(video_path):\n",
    "    frames = []\n",
    "    container = av.open(video_path)\n",
    "    stream = container.streams.video[0]\n",
    "    fps = float(stream.average_rate)\n",
    "    \n",
    "    for frame in container.decode(video=0):\n",
    "        frames.append(frame.to_rgb().to_ndarray())\n",
    "    \n",
    "    return frames, fps\n",
    "\n",
    "def save_video(frames, output_path, fps=30):\n",
    "    container = av.open(output_path, mode='w')\n",
    "    stream = container.add_stream('h264', rate=fps)\n",
    "    \n",
    "    height, width = frames[0].shape[:2]\n",
    "    stream.width = width\n",
    "    stream.height = height\n",
    "    stream.pix_fmt = 'yuv420p'\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = av.VideoFrame.from_ndarray(frame, format='rgb24')\n",
    "        packet = stream.encode(frame)\n",
    "        container.mux(packet)\n",
    "    \n",
    "    packet = stream.encode(None)\n",
    "    container.mux(packet)\n",
    "    container.close()\n",
    "\n",
    "def process_videos(config):\n",
    "    vbad = VBAD(config)\n",
    "    \n",
    "    adv_video_dir = os.path.join(\n",
    "        os.path.dirname(config['video_directory']), \n",
    "        f'VBAD_{config[\"model_type\"]}'\n",
    "    )\n",
    "    os.makedirs(adv_video_dir, exist_ok=True)\n",
    "    \n",
    "    for video_name in tqdm(os.listdir(config['video_directory'])):\n",
    "        if not video_name.endswith(('.mp4', '.avi', '.mov')):\n",
    "            continue\n",
    "            \n",
    "        video_path = os.path.join(config['video_directory'], video_name)\n",
    "        \n",
    "        try:\n",
    "            frames, fps = load_video(video_path)\n",
    "            \n",
    "            true_label = 0 \n",
    "            \n",
    "            possible_targets = list(range(config['num_classes']))\n",
    "            possible_targets.remove(true_label)\n",
    "            target_label = np.random.choice(possible_targets)\n",
    "            \n",
    "            config.update({\n",
    "                'true_label': true_label,\n",
    "                'target_label': target_label\n",
    "            })\n",
    "            \n",
    "            perturbed_frames, density_map = vbad.apply_perturbation(frames)\n",
    "            \n",
    "            output_path = os.path.join(adv_video_dir, video_name)\n",
    "            save_video(perturbed_frames, output_path, fps)\n",
    "            \n",
    "            if config['save_density_map']:\n",
    "                density_path = output_path.rsplit('.', 1)[0] + '_density.npy'\n",
    "                np.save(density_path, density_map)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "config = {\n",
    "    'video_directory': '/home/z/Music/st/Kinetics-400/RQ1/videos_val',\n",
    "    'label_file': '/home/z/Music/st/Kinetics-400/RQ1/kinetics400_val_list_videos.txt',\n",
    "    \n",
    "    'model_type': 'r3d_18',\n",
    "    'num_classes': 400,\n",
    "    \n",
    "    'epsilon': 0.01,  \n",
    "    'density_weight': 0.01,  \n",
    "    \n",
    "\n",
    "    'save_density_map': True,\n",
    "}\n",
    "\n",
    "\n",
    "process_videos(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
